{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoxOjIlOImwx"
      },
      "source": [
        "# Getting Started\n",
        "\n",
        "This notebook is inspired to the Stable Baselines3 tutorial available at [https://github.com/araffin/rl-tutorial-jnrr19](https://github.com/araffin/rl-tutorial-jnrr19).\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this notebook, we will learn how to use **Gymnasium** environments and the basics of **Stable Baselines3**: how to instance an RL algorithm, train and evaluate it.\n",
        "\n",
        "### Links\n",
        "\n",
        "Gymnasium Github: [https://github.com/Farama-Foundation/Gymnasium](https://github.com/Farama-Foundation/Gymnasium)\n",
        "\n",
        "Gymnasium Documentation: [https://gymnasium.farama.org/index.html](https://gymnasium.farama.org/index.html#)\n",
        "\n",
        "Stable Baselines 3 Github:[https://github.com/DLR-RM/stable-baselines3](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "Stable Baseline 3 Documentation: [https://stable-baselines3.readthedocs.io/en/master/](https://stable-baselines3.readthedocs.io/en/master/)\n",
        "\n",
        "## Install Gymnasium and Stable Baselines3 Using Pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSw-cRdT2djP",
        "outputId": "f0d39223-863b-40a8-d88c-3828e5e03fcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.11.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n",
            "Collecting renderlab\n",
            "  Downloading renderlab-0.1.20230421184216-py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from renderlab) (1.0.3)\n",
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (from renderlab) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium->renderlab) (0.0.4)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->renderlab) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy->renderlab) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy->renderlab) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy->renderlab) (2024.2.2)\n",
            "Installing collected packages: renderlab\n",
            "Successfully installed renderlab-0.1.20230421184216\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.25.2)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.15.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.66.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.7.1)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[extra])\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (9.4.0)\n",
            "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
            "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
            "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.11.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[extra])\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.63.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13->stable-baselines3[extra])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[extra]) (6.4.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446659 sha256=0032ac9e30001814a9fed181158bcd7d45cb41a205db14baa485bffd2aeb6296\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/1b/ef/a43ff1a2f1736d5711faa1ba4c1f61be1131b8899e6a057811\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ale-py, shimmy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, AutoROM.accept-rom-license, autorom, nvidia-cusolver-cu12, stable-baselines3\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 shimmy-1.3.0 stable-baselines3-2.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium # import gymnasium\n",
        "!pip install renderlab  #For rendering\n",
        "!pip install stable-baselines3[extra] # last package to be installed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_mU9TNfvE3D",
        "outputId": "6f4d9a56-1b97-40e1-aba8-7d2a0ecaef2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The version of gymnasium is 0.29.1\n",
            "The version of stable_baseline3 is 2.3.2\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "import renderlab\n",
        "import stable_baselines3\n",
        "\n",
        "print(f\"The version of gymnasium is {gym.__version__}\")\n",
        "print(f\"The version of stable_baseline3 is {stable_baselines3.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qoYv8gHvE3F"
      },
      "source": [
        "## Initializing Environments\n",
        "\n",
        "Initializing environments in Gym and is done as follows. We can find a list of available environment [here](https://gym.openai.com/envs/#classic_control)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTbSOamAvE3G"
      },
      "outputs": [],
      "source": [
        "env = gym.make('CartPole-v1')\n",
        "\n",
        "env_eval = gym.make('CartPole-v1', render_mode = \"rgb_array\")\n",
        "env_eval = renderlab.RenderFrame(env_eval, \"./output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUQj4xduvE3G"
      },
      "source": [
        "\"A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. \"\n",
        "\n",
        "Cartpole Environment Decription: [https://gymnasium.farama.org/environments/classic_control/cart_pole/](https://gymnasium.farama.org/environments/classic_control/cart_pole/)\n",
        "\n",
        "Cartpole Source Code: [https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py)\n",
        "\n",
        "![Cartpole](https://cdn-images-1.medium.com/max/1143/1*h4WTQNVIsvMXJTCpXm_TAw.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCgyoKJwvE3H"
      },
      "source": [
        "## Interacting with the Environment\n",
        "\n",
        "We run an instance of `CartPole-v1` environment for 30 timesteps, showing the information returned by the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BisGya56vE3H",
        "outputId": "b771f119-72b8-4038-8844-b0fad7334981"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/gymnasium/envs/classic_control/cartpole.py:180: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
            "  logger.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial state:  [ 0.04644618  0.04944671 -0.00540422 -0.04862791]\n",
            "State: [ 0.04743511  0.24464573 -0.00637678 -0.343011  ] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.05232802  0.4398578  -0.013237   -0.63769794] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.06112518  0.24492294 -0.02599096 -0.3492128 ] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.06602364  0.4404047  -0.03297522 -0.6499769 ] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.07483173  0.6359701  -0.04597475 -0.95285845] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.08755114  0.8316795  -0.06503192 -1.2596242 ] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.10418472  1.0275704  -0.09022441 -1.5719453 ] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.12473613  0.8336333  -0.12166331 -1.308713  ] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.1414088   0.64024466 -0.14783758 -1.0564551 ] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.1542137   0.447358   -0.16896668 -0.8135872 ] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.16316086  0.25490305 -0.18523842 -0.57845604] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.16825892  0.06279405 -0.19680753 -0.34937152] Action: 0 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.16951479  0.26009092 -0.20379497 -0.6970925 ] Action: 1 Reward: 1.0 Terminated: False Truncated: False\n",
            "State: [ 0.17471662  0.06829034 -0.21773683 -0.47484723] Action: 0 Reward: 1.0 Terminated: True Truncated: False\n",
            "State: [ 0.17608242 -0.12320039 -0.22723377 -0.25790313] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.17361842 -0.31447878 -0.23239182 -0.0445945 ] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.16732883 -0.11690993 -0.23328371 -0.4006912 ] Action: 1 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.16499063 -0.30809492 -0.24129754 -0.1896468 ] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.15882874 -0.4990994  -0.24509047  0.01830439] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.14884675 -0.69002306 -0.2447244   0.22479399] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.13504629 -0.49239072 -0.2402285  -0.13405453] Action: 1 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.12519848 -0.29477727 -0.2429096  -0.49191242] Action: 1 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.11930293 -0.4857991  -0.25274786 -0.2845068 ] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.10958695 -0.288129   -0.258438   -0.6451109 ] Action: 1 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.10382437 -0.09051174 -0.2713402  -1.0068305 ] Action: 1 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.10201413 -0.2811933  -0.29147682 -0.81007165] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.09639027 -0.47140244 -0.30767825 -0.62127817] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.08696222 -0.66122526 -0.3201038  -0.43895224] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.07373772 -0.85074973 -0.32888284 -0.26161805] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n",
            "State: [ 0.05672272 -1.0400643  -0.3341152  -0.08782381] Action: 0 Reward: 0.0 Terminated: True Truncated: False\n"
          ]
        }
      ],
      "source": [
        "# When I want to interact with the environment I have to reset it. the method '.reset' outputs the initial stater\n",
        "state, _ = env.reset() # resets the environment in the initial state: I force the environment to start from the initial state\n",
        "print(\"Initial state: \", state)\n",
        "\n",
        "# I sample a random action among the action space (once for each iteration)\n",
        "for _ in range(30):\n",
        "    action = env.action_space.sample() # sample a random action\n",
        "\n",
        "    state, reward, terminated, truncated, _ = env.step(action)  # execute the action in the environment (I send the action to the environment). The '_' is a dictgionary to have further infomation\n",
        "    print(\"State:\", state,\n",
        "          \"Action:\", action,\n",
        "          \"Reward:\", reward,\n",
        "          \"Terminated:\", terminated, # If the environment has reached the terminal state (terminated = 1 ==> The cart poile has taken a position outside the angle range)\n",
        "          \"Truncated:\", truncated)\n",
        "\n",
        "env.close()\n",
        "\n",
        "# We are playing a random action: after some iterations, the pole surely goes outside the prescribed range: terminated will be soon True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ikNk64jvE3H"
      },
      "source": [
        "A Gymnasium environment provides to the user mainly four methods:\n",
        "\n",
        "* `reset()`: resets the environment to its initial state $S_0 \\sim d_0$ and returns the observation corresponding to the initial state.\n",
        "\n",
        "\n",
        "* `step(action)`: takes an action $A_t$ as an input and executes the action in current state $S_t$ of the environment. This method returns a tuple of four values:\n",
        "\n",
        "    * `observation` (object): an environment-specific object representation of your observation of the environment after the action is executed. It corresponds to the observation of the next state $S_{t+1} \\sim p(\\cdot|S_t,A_t)$\n",
        "    \n",
        "    * `reward` (float): immediate reward $R_{t+1} = r(S_t,A_t)$ obtained by executing action $A_t$ in state $S_t$\n",
        "    \n",
        "    * `terminated`(boolean): whether the reached next state $S_{t+1}$ is a terminal state.\n",
        "    \n",
        "    * `truncated`(boolean): whether the trajectory has reached the maximum number of steps.**testo in grassetto**\n",
        "    \n",
        "    * `info` (dict): additional information useful for debugging and environment-specific.\n",
        "    \n",
        "    \n",
        "*  `render(method='human')`: allows visualizing the agent in action. Note that graphical interface does not work on Google Colab, so we cannot use it directly (we will need a workaround).\n",
        "\n",
        "\n",
        "*  `seed()`: sets the seed for this environment’s random number generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYnUyQQDvE3H"
      },
      "source": [
        "## Observation and Action Spaces\n",
        "\n",
        "*  `observation_space`: this attribute provides the format of valid observations $\\mathcal{S}$. It is of datatype `Space` provided by Gymnasium. For example, if the observation space is of type `Box` and the shape of the object is `(4,)`, this denotes a valid observation will be an array of 4 numbers.\n",
        "\n",
        "*  `action_space`: this attribute provides the format of valid actions $\\mathcal{A}$. It is of datatype `Space` provided by Gymnasium. For example, if the action space is of type `Discrete` and gives the value `Discrete(2)`, this means there are two valid discrete actions: 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V7sIG6evE3I",
        "outputId": "6ad38939-e033-4d8d-8bd3-c321bfdb1fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
            "Discrete(2)\n",
            "[4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38]\n",
            "[-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38]\n"
          ]
        }
      ],
      "source": [
        "print(env.observation_space) # The observation space is an object of class 'Box' characterized by two vectors; it's used for modelling continuous spaces (For the cartpole, the state-space is a subset of R^4)\n",
        "\n",
        "print(env.action_space) # Discrete(2) ==> the action space is made of two discrete actions (max force aplied to the left or to the right)\n",
        "\n",
        "print(env.observation_space.high)\n",
        "\n",
        "print(env.observation_space.low)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtNdPfS-vE3I"
      },
      "source": [
        "`Spaces` types available in Gymnasium:\n",
        "\n",
        "*  `Box`: an $n$-dimensional compact space (i.e., a compact subset of $\\mathbb{R}^n$). The bounds of the space are contained in the `high` and `low` attributes.\n",
        "\n",
        "\n",
        "*  `Discrete`: a discrete space made of $n$ elements, where $\\{0,1,\\dots,n-1\\}$ are the possible values.\n",
        "\n",
        "\n",
        "Other `Spaces` types can be used: `Dict`, `Tuple`, `MultiBinary`, `MultiDiscrete`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t15LJ3sxvE3I",
        "outputId": "53228397-afb6-40ed-a053-a0d60f30c880"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.291738  1.4767408 1.7877692]\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from gymnasium.spaces import Box, Discrete\n",
        "\n",
        "# Build a state-space that is a subset of R^3,\n",
        "observation_space = Box(low=-1.0, high=2.0, shape=(3,), dtype=np.float32)\n",
        "print(observation_space.sample()) # This method provides points that are uniformly sampled from the observation space\n",
        "\n",
        "# Similarly, I build now a discerte state space with 4 variables\n",
        "observation_space = Discrete(4)\n",
        "print(observation_space.sample())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwoqXiGwvE3I"
      },
      "source": [
        "## Details on the Cartpole Environment\n",
        "\n",
        "From [https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py](https://github.com/Farama-Foundation/Gymnasium/blob/main/gymnasium/envs/classic_control/cartpole.py)\n",
        "\n",
        "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The pendulum starts upright, and the goal is to prevent it from falling over by increasing and reducing the cart's velocity.\n",
        "\n",
        "### Action Space\n",
        "The action space is `action` in $\\{0,1\\}$, where `action` is used to push the cart with a fixed amount of force:\n",
        "\n",
        " | Num | Action                 |\n",
        "    |-----|------------------------|\n",
        "    | 0   | Push cart to the left  |\n",
        "    | 1   | Push cart to the right |\n",
        "    \n",
        "Note: The amount the velocity is reduced or increased is not fixed as it depends on the angle the pole is pointing. This is because the center of gravity of the pole increases the amount of energy needed to move the cart underneath it.\n",
        "    \n",
        "### Observation Space\n",
        "The observation is a `ndarray` with shape `(4,)` where the elements correspond to the following:\n",
        "\n",
        "   | Num | Observation           | Min                  | Max                |\n",
        "    |-----|-----------------------|----------------------|--------------------|\n",
        "    | 0   | Cart Position         | -4.8*                | 4.8*                |\n",
        "    | 1   | Cart Velocity         | -Inf                 | Inf                |\n",
        "    | 2   | Pole Angle            | ~ -0.418 rad (-24°)**| ~ 0.418 rad (24°)** |\n",
        "    | 3   | Pole Angular Velocity | -Inf                 | Inf                |\n",
        "\n",
        "**Note:** above denotes the ranges of possible observations for each element, but in two cases this range exceeds the range of possible values in an un-terminated episode:\n",
        "- `*`: the cart x-position can be observed between `(-4.8, 4.8)`, but an episode terminates if the cart leaves the `(-2.4, 2.4)` range.\n",
        "- `**`: Similarly, the pole angle can be observed between  `(-.418, .418)` radians or precisely **±24°**, but an episode is  terminated if the pole angle is outside the `(-.2095, .2095)` range or precisely **±12°**\n",
        "    \n",
        "### Rewards\n",
        "Reward is 1 for every step taken, including the termination step.\n",
        "\n",
        "### Starting State\n",
        "All observations are assigned a uniform random value between (-0.05, 0.05)\n",
        "\n",
        "### Episode Termination\n",
        "The episode terminates of one of the following occurs:\n",
        "1. Pole Angle is more than ±12°\n",
        "2. Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n",
        "3. Episode length is greater than 500\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDySnoVvE3I"
      },
      "source": [
        "## Evaluation of some Simple Policies\n",
        "\n",
        "We now evaluate some policies on the cartpole.\n",
        "\n",
        "* **Uniform Policy**: uniformly random policy\n",
        "\n",
        "$$\n",
        "\\pi(a|s) = \\mathrm{Uni}(\\{0,1\\})\n",
        "$$\n",
        "\n",
        "* **Reactive Policy**: simple deterministic policy that selects the action based on the pole angle\n",
        "\n",
        "$$\n",
        "\\pi(s) = \\begin{cases}\n",
        "                0 & \\text{if Pole Angle } \\le 0 \\\\\n",
        "                1 & \\text{otherwise}\n",
        "            \\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW_UAusJvE3I"
      },
      "outputs": [],
      "source": [
        "# These two policies are hard-coded, not obtained with Reinforcement Learning\n",
        "# policy (according to abseline3) = object that exposes a method providing a pair as output\n",
        "class UniformPolicy:\n",
        "\n",
        "    def predict(self, obs):\n",
        "        return np.random.randint(0, 2), obs  # return the observation to comply with stable-baselines3\n",
        "\n",
        "\n",
        "class ReactivePolicy:\n",
        "\n",
        "    def predict(self, obs):\n",
        "        if obs[2] <= 0: # If the pole angle (third element) is smaller than zero\n",
        "            return 0, obs\n",
        "        else:\n",
        "            return 1, obs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPvHvRH3vE3J"
      },
      "source": [
        "Let us create a function to evaluate the agent's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKi5PLUkvE3J"
      },
      "outputs": [],
      "source": [
        "# Function implemented just to run some episodes with an environment executing a certain policy and using a discount factor\n",
        "\n",
        "def evaluate(env, policy, gamma=1., num_episodes=100):\n",
        "    \"\"\"\n",
        "    Evaluate a RL agent\n",
        "    :param env: (Env object) the Gym environment\n",
        "    :param policy: (BasePolicy object) the policy in stable_baselines3\n",
        "    :param gamma: (float) the discount factor\n",
        "    :param num_episodes: (int) number of episodes to evaluate it\n",
        "    :return: (float) Mean reward for the last num_episodes\n",
        "    \"\"\"\n",
        "    all_episode_rewards = []\n",
        "    for i in range(num_episodes): # iterate over the episodes\n",
        "        episode_rewards = []\n",
        "        done = False\n",
        "        discounter = 1.\n",
        "        obs, _ = env.reset()\n",
        "        while not done: # iterate over the steps until termination and play the same action!\n",
        "            action, _ = policy.predict(obs)\n",
        "            obs, reward, terminated, truncated, _ = env.step(action)\n",
        "            done = terminated or truncated\n",
        "            episode_rewards.append(reward * discounter) # compute discounted reward\n",
        "            discounter *= gamma\n",
        "\n",
        "        all_episode_rewards.append(sum(episode_rewards))\n",
        "\n",
        "    mean_episode_reward = np.mean(all_episode_rewards)\n",
        "    std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n",
        "    print(\"Mean reward:\", mean_episode_reward, # collected over the episodes: if the result is 22.23 ==> I can keep on average the pole in the correct range for 22.23 steps\n",
        "          \"Std reward:\", std_episode_reward,\n",
        "          \"Num episodes:\", num_episodes)\n",
        "\n",
        "    return mean_episode_reward, std_episode_reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afBSiT_tvE3J"
      },
      "source": [
        "Let us test the uniform policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "g33tYX96vE3J",
        "outputId": "af01db29-f3ee-4e91-a0a4-202054537b62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 21.68 Std reward: 1.1475824391064264 Num episodes: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-11-afd6aa70d858>:28: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 34.0 Std reward: nan Num episodes: 1\n",
            "Moviepy - Building video temp-{start}.mp4.\n",
            "Moviepy - Writing video temp-{start}.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "t:  72%|███████▏  | 26/36 [00:00<00:00, 255.15it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file ./output/1715706005.4863455.mp4, 720000 bytes wanted but 0 bytes read,at frame 35/36, at time 1.17/1.17 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready temp-{start}.mp4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAEQ5tZGF0AAACrgYF//+q3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSByMjk5MSAxNzcxYjU1IC0gSC4yNjQvTVBFRy00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAxOSAtIGh0dHA6Ly93d3cudmlkZW9sYW4ub3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFseXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVkX3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBkZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMgbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAB/2WIhAAr//7Y5/Msq1xA0DVUuHVl7uFSgaMoZ2nkvUzAAAADAAADAABo/Ot9/srZ0dc2TAAAAwIUAF6DPCjCvjqEhH2OkMnAzV3ADIPK1o5NYZdBXguOjLQbrZmTEUUU7NniNJWbMk0NZ3z3DFTFVfUC4P7pjadVbqfvfJrIJFoOh9qAWKldYa5zGeMM8HARbCGwWT/TdkPxe5J7yxfaKIAZPZ61/vTrwf+iE1G4i1erWC7lI5BRPWWIxR0tWwCn/39mDdGoyH40Z1lT454neSPwR35eP0tr3Ma0kDcUGFACQIDTVNuZ65XFSvPuO7K4OtXBTNFvWIAlkSAMg8koMHn4MFc/sJJ6MtChEs/vCj/h1NYAC+XcAUugABvccnyAgKeb7eZTkXil3O/EfVBw0ahlmXrRbTvkj7HtmH2pF3dMIXcw8hBBaAB45WlYY2MaRu29/VTUuZfvoDSiayRkfGDLa0xNFqJjPfTgXHoiqelYDiQc0uS46046/qh/ezUuqLB9KdbNJHXzLLVYLElv/1on0/NzlLK47irE4JuLYQ30p/gimAKEs3/RXJfe0at/gSan5etv92TfEkNZ4AACJOqDYVC+bWTByyqVC7HRmvp4ouR3b90/zwhUIlj1sa0SVSNRfDXfFYuXVk7QEHAIfjYZoIAAPmwAAAMAAAMAmYEAAAB9QZojbEK//jhAAAENGlZ8E718IDYfHMUu3auueqeKVQXlYjNIzakE86b4ChCKK1fQyJ7OfEXg7YR8lkjWpBYZrqYmsJapX+j+Is5Ss2z+weoc30GRQ3KRpFN7GmDUr5wadSL+K27eMHDd44CBY8qPUj9QBd3Dj/eic5HBYmAAAAAcQZ5BeI//AAAjwxdhQCWxWXZaCdnPIsA+97gkmQAAAC0BnmJqRv8AAC14xSVTcarVPaJJsqKEIVR/p9fACKgP6twrDqeeAn/VtBbEAAcAAAEGQZpnSahBaJlMCE///fEAAAMCoKNU/BfkeAe4OSxV3SiBO7aL5qdPvTqB6PzC6UsDQbyFs0Wcve3VbG7smgHqqL8mmgyR/hExbZ+2dvfiee5HwJ2OXQzOW70XYvRzmk6ZxFozyJGVtPWKVaVdWc1uiuAUaDgfI9KFNRPbVkbpcxRpZILmHbBiTce7V1/q+V+6gMEiky2xvyod+2sprp1BEJz2UHdL2Byk3UW49c4eyVxL8rac5XuIMNHCX8RUKhi6yqxTSK8C3uAe6cWAPFVeC56ubP41ksR/0PfjoHI4F3LeBzRazf88Wh56olsVd9SUH74rcVc+5Gbp9vnKW6ejBlm8QqoGWQAAAExBnoVFESx/AAAjvYOByZfFvQAKBI0bwO4VBccdvhF7aMbwg0fvQ8Xmh9kJP2O87oRuZFbjtvOhK1m8P93aWPArlkPFdDzb6GDTAT0hAAAAMwGepHRG/wAALX3pfVfgxK6bppCPkXugVm1E7dmj/My0xCfHMah8yh9Bz2JbTmJtib2LzQAAAEEBnqZqRv8AAC1gldqtaOCyCjmof48tY+L9Mw7Ox00kLdFDBKOvNh/yvc4d+35Zg3AMWj7/+hzCBYuYGgGQCaCG+QAAALVBmqhJqEFsmUwIV//+OEAAAQz6HfJsRAohh15mOw7EqllND2EXC5WxMEv2SBaRWbIHTGx+8YfeNEujKTeWpBpIiVypHidgiUaDiaRSV6TbiHHgRhR4hZlLKBpHJFIbifWXMHfDB01GAd5aHlZB9aIQILmMJwH39+8lKf2Shwk4LYYR7ShRCC/5+HoXwaNo7a0c5aF8Tp08OQkA/wjeFJtpyli1YxImLvbK16PDC8haYDc3yu+bAAAAmkGayknhClJlMFFSwr/+OEAAAQz2jSGq/wGo6vIUp9uq+TdefX1ZO++rTAYyJkDmhv0eu7HiR7uAlbLXUYfHG3tQFYkVu9LbbunMCE/JUugOm+kvBR80Dz0PKL//Tr3zoPY0Oqv//PqTC481/F03vXIbgyikp4KLAeR18rVWJEepYI4QT3jrl/Yb2Lso/MgHgmSDXoEz7R4TQxQAAABGAZ7pakb/AAAs4Dyg7Vupn5AK0sF3z6EbQoY3nIo82kKfstPjhWczyauO8M3uHr9DVoyA2f2nAAhElFPyL/45EJjUrks/OQAAALNBmu5J4Q6JlMCFf/44QAABDeWjnBWP0wBt8kxHiKM8kRnhb3UB8r5S2qJP14w1GSK3TlzXBXnZXmGpuOWMnHVzvpLisOlNK47FcWNw92Q9+qkQrIiwENx9IoUON+ht/wcDA8iFO4i/OpRZ8Hx1DMZooJcSogmLSbsHmwTx94UpKnBzWZNqWSf3nyRG6mBKkgVaj1AGxKyEeFpA03nLvsLYLObiq8fUpKwY7nTniMlA2z3HQAAAAERBnwxFFTx/AAAjmSenALejLzFzZ/vSEaoCXj2tGMRBfaTAJEW2zUvW7GYbZn5EbVbjKVeqd3QU6RWu5Gxh5M14DNZrKAAAADIBnyt0Rv8AAC1fARrFb1ao976citpr4ucxVrNT0HJ/n+wqhVfdfbHooD2ey8fx/I+n+wAAADMBny1qRv8AAC12ecCopxWUiQ2DwRIm8Kw2JY0BLJyAmwQdjJL3ZOJHMx7lAV56Jf1QGCcAAACDQZsySahBaJlMCFf//jhAAAEVTt8AhLBKrENiHeBIkGPxFLoxUkUPG2eRZTGYrueWLwbP4dNKp9b+wE3JtWW1NRrob3o176r0inZIpstPNZWNsGSUvLL2DKlXdYfje9EBKhV9kUgzfzQzBciKeu2kVBEA3wuCHGUIMtC19m/Ok8UiD80AAABQQZ9QRREsfwAAJL7faIIg3i9UM48tWfUIP8B5MGCBP3AVpsaQYNg+PpWDXjImbg08KoAidHUAX3eBAJ8ZLpdgXmfAMmKGk4J4KFhD6Nh4LNAAAAAuAZ9vdEb/AAAtcjfxlxNs8oAikt7RZykZz0U/SlbTAE8KZIPoRJfETGlCAFzEvAAAAD4Bn3FqRv8AAC5y84mXJ/nYXJs7W6OCoiwQkaQaHofylMD7svFX4JYLNRTb9EmJc15lWa7P2YSjaM840wOEjQAAAIpBm3ZJqEFsmUwIV//+OEAAARVO8C2xL4YwcV9kR+4zwWoNvBYAfVRhu1M3ULV7ZA07c+TkiOMPI0g+9d+lyeWvCPBHs5Q9qhBa0qRwwE+oSJmyqf8e+IMham2Mu9uLG55ZHrtYgmGj1flkTch+qdFKL0HsPSUuFF4l3xdSM6ZVlf6+3bKta8bNoAgAAAA/QZ+URRUsfwAAJL05QzMUo5K3YYd2ty8+FpRktwJyYFEuVpBCt1Aw9NHuhjtGI1fI7E7o4oovzOAkqIUdDxiNAAAAMAGfs3RG/wAALpp3F8chuwu2LuqyGsRpmJ9UeVyPbvSpwGm509fK59qQwYmmK0nCXQAAADsBn7VqRv8AAC6WecBntOlnRMjg95JhjB9UNVWg79mt6S5CSRkDWh0GZjJaxcbE+y11ct5Z5Q2FaI/QugAAAJpBm7pJqEFsmUwIV//+OEAAARWRVWyFJAM0SvFEmZ/F1a98bGQVkV1hGipOJbnFOL1qz5ZxXFx108qJ+9uf1Ure8v7HoP/oHj7jknUIHIhJnsQDv5NYotbf/iVwoEyNXFPk/h53LlxDBpZ57E979HuUojajRETB6Lj2mZNRgXHb7y1hwF+au4dOembo/BonLr1WBygZqkJx+gKBAAAAPUGf2EUVLH8AACSS4xRVMF5p3A38GyUgVpQyy4na7wL9iXot4yRQddt7rnRHdL0Uwu3gAG3a7Kibg/RkI4EAAAA0AZ/3dEb/AAAue6QXIJ3stJf93/xKtR2Dk6Ag6FN1+76zqg+v3oW7wiPq7N8QFvrsdU35gAAAAC8Bn/lqRv8AAC5t2HfAP2onHSN8W6ewbNhEqMsCk3ccs/Rx6H5XJ0gouEqZmGtNIQAAAIJBm/5JqEFsmUwIT//98QAAAwLC8Rn3nbP8Alzp+zXzvrN57KF4Z00uNVAFwrJtanYVEDfh3x7RcnOMdNBUTnV0iI3A3Y/OwrMYGy/CFoaErUb3aDqncpStjm8RWuxjd1nNzKRHUwRox/DqJmO2OSlHgtH8oSA58uEFWMTQF333gLCZAAAAREGeHEUVLH8AACW+5lz2hbTEboxLzm7LPOe3U2UAPdAePf1PkZPaqNZqLEvjHueGCaVDG5plQXVpC6S1IvcA3n0WB50xAAAAMAGeO3RG/wAALpks9PUYNnBr2F5wL3DRhjLjJCsIVwXA7oomUNovk16iW39i58+PQQAAADABnj1qRv8AAC/R89hH71cg1Z8nQagcatkH3UhSs9WAmDXWcut6oux9bBJ4vckCWUAAAACbQZoiSahBbJlMCP/8hAAAENG11rVQAQp+Uwh/rpy4vkBr3Uzia7LfLaNFMHWPJbtOKxbXuaqqA/zX7J3TJtLOZJaFzqzO2vkuHqF+1qUFTQ3RtbH1BFXu1dn+imbWY5I55L/mSx2HSavNDfkHup1Kd9j1e5nEnQ+QvZIg9U43TellkEHrtHOZtHYicCvX9p6GFMBWt6pDOWgc7oAAAABYQZ5ARRUsfwAAJayZQMTxhXCeorawO+FX3CUW6KHPz7J49Wjchs30VVKtKk4G7EABwI1eQSvC5J/0C2jzpxqNZiq6qb/UjV9ocqMkRKpAL50TA/fApmcCOQAAACoBnn90Rv8AAC+wApv7/vAyZudN580iqw6lZRfnaSViNMcYuuPa9EEjmT4AAAA+AZ5hakb/AAAvzhvu9oVatA0odPg6D2KnvLbkC5n1MNow/jAeXP6mtFt6bClvlOZdiKGEgmfhQGjY3FAKfQcAAAAaQZpjSahBbJlMCN/6WAAAIDzfmlNhm262BlQAAAS7bW9vdgAAAGxtdmhkAAAAAAAAAAAAAAAAAAAD6AAABLAAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAA+V0cmFrAAAAXHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAABLAAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAGQAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEAAASwAAAEAAABAAAAAANdbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAA8AAAASABVxAAAAAAALWhkbHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAADCG1pbmYAAAAUdm1oZAAAAAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAAshzdGJsAAAAmHN0c2QAAAAAAAAAAQAAAIhhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgBkABIAAAASAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMmF2Y0MBZAAe/+EAGWdkAB6s2UCYM+XhAAADAAEAAAMAPA8WLZYBAAZo6+PLIsAAAAAYc3R0cwAAAAAAAAABAAAAJAAAAgAAAAAUc3RzcwAAAAAAAAABAAAAAQAAAShjdHRzAAAAAAAAACMAAAABAAAEAAAAAAEAAAgAAAAAAgAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAQAAAAAHHN0c2MAAAAAAAAAAQAAAAEAAAAkAAAAAQAAAKRzdHN6AAAAAAAAAAAAAAAkAAAEtQAAAIEAAAAgAAAAMQAAAQoAAABQAAAANwAAAEUAAAC5AAAAngAAAEoAAAC3AAAASAAAADYAAAA3AAAAhwAAAFQAAAAyAAAAQgAAAI4AAABDAAAANAAAAD8AAACeAAAAQQAAADgAAAAzAAAAhgAAAEgAAAA0AAAANAAAAJ8AAABcAAAALgAAAEIAAAAeAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjI5LjEwMA==\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "uniform_policy = UniformPolicy()\n",
        "\n",
        "uniform_policy_mean, uniform_policy_std = evaluate(env, uniform_policy)\n",
        "\n",
        "_, _ = evaluate(env_eval, uniform_policy, num_episodes=1)\n",
        "env_eval.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf3hyxHavE3K"
      },
      "source": [
        "Let us test the reactive policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "bpsJqDB2vE3K",
        "outputId": "c5633cb5-4a6c-47c2-8801-80f8cea2557d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-11-afd6aa70d858>:28: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 42.84 Std reward: 0.8240966894335602 Num episodes: 100\n",
            "Mean reward: 31.0 Std reward: nan Num episodes: 1\n",
            "Moviepy - Building video temp-{start}.mp4.\n",
            "Moviepy - Writing video temp-{start}.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rt:   0%|          | 0/33 [00:00<?, ?it/s, now=None]WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/moviepy/video/io/ffmpeg_reader.py:123: UserWarning: Warning: in file ./output/1715706202.8595276.mp4, 720000 bytes wanted but 0 bytes read,at frame 32/33, at time 1.07/1.07 sec. Using the last valid frame instead.\n",
            "  warnings.warn(\"Warning: in file %s, \"%(self.filename)+\n",
            "\n",
            "                                                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready temp-{start}.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reactive_policy = ReactivePolicy() # I do a little better (I keep it in the correct range for almost 43 steps, but the behaviour is unstable)\n",
        "\n",
        "reactive_policy_mean, reactive_policy_std = evaluate(env, reactive_policy)\n",
        "\n",
        "_, _ = evaluate(env_eval, reactive_policy, num_episodes=1)\n",
        "env_eval.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhze0bb_vE3K"
      },
      "source": [
        "## PPO Training\n",
        "\n",
        "We now use Stable Baselines3 to train some simple algorithms. We start by using [Proximal Policy Optimization](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html).\n",
        "\n",
        "We select the [MlpPolicy](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#ppo-policies) because the state of the CartPole environment is a feature vector (not images for instance). The type of action to use (discrete/continuous) will be automatically deduced from the environment action space.\n",
        "\n",
        "We consider two network architectures:\n",
        "\n",
        "* Linear policy\n",
        "* Two hidden layers of 32 neurons each"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-NBhhS_vE3K",
        "outputId": "e80dcba5-f43b-4feb-a727-7ac2c52be440",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "ActorCriticPolicy(\n",
            "  (features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (pi_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (vf_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "    (value_net): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (action_net): Linear(in_features=32, out_features=2, bias=True)\n",
            "  (value_net): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n",
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "ActorCriticPolicy(\n",
            "  (features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (pi_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (vf_features_extractor): FlattenExtractor(\n",
            "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (mlp_extractor): MlpExtractor(\n",
            "    (policy_net): Sequential()\n",
            "    (value_net): Sequential()\n",
            "  )\n",
            "  (action_net): Linear(in_features=4, out_features=2, bias=True)\n",
            "  (value_net): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# the previous hand-coded pèolicies were not so good. We'll now try to train a RL algorithm like PPO on the environment (Proximal Policy Optimization)\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# We will consider two scenarios (we are in a disceret case): a simple linear policy (linear in the state representation). Since the action-state is finite, we consider a Boltzmann (or softmax) policy (prob. of playing an action = e ^ (theta^T * s) / (1 + e ^ (theta^T * s))\n",
        "\n",
        "# In the sweconbd scenario we replace a linear function with a 2-hidden layer neural network: I still have a similar policy (Boltzmann form), but no more linear combinations. (pi(a|s) = e ^ (NN_theta(s)) / (1 + e ^ (NN_theta(s)))\n",
        "\n",
        "# If I had continuous actions, the previous policies would become Gaussians: for the first ==> N(theta^T * s. sigma ^ 2); for the second ==> N(NN_theta(s), sigma ^ 2)\n",
        "\n",
        "# Instantiate the algorithm with 32x32 NN approximator for both actor and critic (MLP policy = Multi-Layer Perceptron)\n",
        "ppo_mlp = PPO(\"MlpPolicy\", env, verbose=1,\n",
        "                learning_rate=0.01,\n",
        "                policy_kwargs=dict(net_arch = [dict(pi=[32, 32], vf=[32, 32])])) # pi = actor; vf = value function = critic; the neurons are 32; the activation function is hyperbolic tangent ,not ReLU\n",
        "\n",
        "print(ppo_mlp.policy)\n",
        "\n",
        "# Instantiate the algorithm with linear approximator for both actor and critic\n",
        "ppo_linear = PPO(\"MlpPolicy\", env, verbose=1,\n",
        "                   learning_rate=0.01,\n",
        "                   policy_kwargs=dict(net_arch = [dict(pi=[], vf=[])])) # Linear function = Neural network with some hidden layers\n",
        "\n",
        "print(ppo_linear.policy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMsk-dD0vE3K"
      },
      "source": [
        "Let us now train the algorithms. In order to keep track of the performance during learning, we can log the evaluations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6524b65fc3fb4f11bb721c4608463fef",
            "f17ddede3cdf4a5cbd295211c51d9e8e",
            "d18154d71d4a4541a7a727779aa34dda",
            "6a73f78210424ad3b954db2285ae7961"
          ]
        },
        "id": "gnpEj4BWvE3L",
        "outputId": "413add18-d2d8-4b50-c40e-607d74416ca0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6524b65fc3fb4f11bb721c4608463fef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 59          |\n",
            "|    ep_rew_mean          | 59          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 386         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 21          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015048113 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.583      |\n",
            "|    explained_variance   | 0.503       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 8.87        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.023      |\n",
            "|    value_loss           | 29.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 124         |\n",
            "|    ep_rew_mean          | 124         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 389         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 42          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013770072 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.543      |\n",
            "|    explained_variance   | 0.946       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 2.95        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0214     |\n",
            "|    value_loss           | 8.65        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 193         |\n",
            "|    ep_rew_mean          | 193         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 387         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 63          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021559667 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.497      |\n",
            "|    explained_variance   | 0.987       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 1.56        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | 0.00219     |\n",
            "|    value_loss           | 2.92        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 259         |\n",
            "|    ep_rew_mean          | 259         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 379         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 86          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019446403 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.506      |\n",
            "|    explained_variance   | 0.989       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 0.367       |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.00138    |\n",
            "|    value_loss           | 0.825       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 321         |\n",
            "|    ep_rew_mean          | 321         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 383         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024021927 |\n",
            "|    clip_fraction        | 0.224       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.445      |\n",
            "|    explained_variance   | -0.000561   |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 0.0452      |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | 0.00679     |\n",
            "|    value_loss           | 0.0359      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 383         |\n",
            "|    ep_rew_mean          | 383         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 378         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011166196 |\n",
            "|    clip_fraction        | 0.109       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.473      |\n",
            "|    explained_variance   | 0.553       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | -0.0113     |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | 0.00127     |\n",
            "|    value_loss           | 0.00922     |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d18154d71d4a4541a7a727779aa34dda",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 34.2        |\n",
            "|    ep_rew_mean          | 34.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 526         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 15          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005066416 |\n",
            "|    clip_fraction        | 0.032       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 3.3e-05     |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 21.1        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00755    |\n",
            "|    value_loss           | 66          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 83.6         |\n",
            "|    ep_rew_mean          | 83.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 495          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 33           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070594214 |\n",
            "|    clip_fraction        | 0.0494       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | 0.0425       |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 46           |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00955     |\n",
            "|    value_loss           | 108          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 149         |\n",
            "|    ep_rew_mean          | 149         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 491         |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006845317 |\n",
            "|    clip_fraction        | 0.0417      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.611      |\n",
            "|    explained_variance   | 0.17        |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 27.9        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.00235    |\n",
            "|    value_loss           | 90          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 171          |\n",
            "|    ep_rew_mean          | 171          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 488          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 67           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035315831 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.577       |\n",
            "|    explained_variance   | 0.404        |\n",
            "|    learning_rate        | 0.01         |\n",
            "|    loss                 | 74.9         |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    value_loss           | 108          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 113         |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 417         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 117         |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004302166 |\n",
            "|    clip_fraction        | 0.038       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.55       |\n",
            "|    explained_variance   | 0.859       |\n",
            "|    learning_rate        | 0.01        |\n",
            "|    loss                 | 14.1        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00781    |\n",
            "|    value_loss           | 51          |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7f1aa5d4fb80>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the agent for 50000 steps (learn is a method)\n",
        "ppo_mlp.learn(total_timesteps=50000, log_interval=4, progress_bar=True)\n",
        "\n",
        "ppo_linear.learn(total_timesteps=50000, log_interval=4, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "aLDoA0CpvE3M",
        "outputId": "02c1f150-6193-4dd5-bd57-20e7a617ef91"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'evaluate' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-16ba693cdfc8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the trained models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mppo_mlp_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppo_mlp_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppo_mlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mppo_mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
          ]
        }
      ],
      "source": [
        "# Evaluate the trained models\n",
        "ppo_mlp_mean, ppo_mlp_std = evaluate(env, ppo_mlp)\n",
        "\n",
        "_, _ = evaluate(env_eval, ppo_mlp, num_episodes=1)\n",
        "env_eval.play()\n",
        "\n",
        "\n",
        "ppo_linear_mean, ppo_linear_std = evaluate(env, ppo_linear)\n",
        "\n",
        "_, _ = evaluate(env_eval, ppo_linear, num_episodes=1)\n",
        "env_eval.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gmOZ_6DvE3M"
      },
      "source": [
        "Let us have a look at the weights learned by PPO with the linear policy. Since actions are discrete, the policy model is **softmax**:\n",
        "\n",
        "$$\n",
        "\\pi_{\\boldsymbol{\\theta}}(a|\\mathbf{s}) \\propto \\exp \\left( \\mathbf{s}^T \\boldsymbol{\\theta}(a) + b(a) \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "N7pFa60tvE3M",
        "outputId": "883c80d5-3bc3-4a3c-def1-9f2310d4cf1f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ppo_linear' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d4e2af37520f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_linear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ppo_linear' is not defined"
          ]
        }
      ],
      "source": [
        "print(ppo_linear.policy.action_net.weight)\n",
        "print(ppo_linear.policy.action_net.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKNVraYivE3N"
      },
      "source": [
        "## DQN Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg9-M4rAvE3N"
      },
      "source": [
        "Let us now try [DQN](https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html) with an MlpPolicy as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU0fNecsvE3N",
        "outputId": "3db2a26c-b0f0-4557-d781-79e0879bbf40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "DQNPolicy(\n",
            "  (q_net): QNetwork(\n",
            "    (features_extractor): FlattenExtractor(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (q_net): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "      (4): Linear(in_features=32, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (q_net_target): QNetwork(\n",
            "    (features_extractor): FlattenExtractor(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "    )\n",
            "    (q_net): Sequential(\n",
            "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
            "      (1): Tanh()\n",
            "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
            "      (3): Tanh()\n",
            "      (4): Linear(in_features=32, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# We now try to use DQN\n",
        "\n",
        "from stable_baselines3 import DQN\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "# Instantiate the algorithm with 32x32 NN approximator\n",
        "dqn_mlp = DQN(\"MlpPolicy\", env, verbose=1,\n",
        "                learning_starts=3000, # N of steps after which to start learning; remember: DQN needs a replay buffer, that needs to be quite filled before you can start learning\n",
        "                policy_kwargs=dict(net_arch = [32, 32], activation_fn=nn.Tanh))\n",
        "\n",
        "print(dqn_mlp.policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a0456c21d7684db0b9bd0bff83dfbe57",
            "ea851811079942b3b20cb106069cba92"
          ]
        },
        "id": "Ye-yH_qsvE3N",
        "outputId": "1a0faedf-6aea-4f2c-abd8-e4fdcb26d949"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0456c21d7684db0b9bd0bff83dfbe57",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 20.8     |\n",
            "|    ep_rew_mean      | 20.8     |\n",
            "|    exploration_rate | 0.606    |\n",
            "| time/               |          |\n",
            "|    episodes         | 100      |\n",
            "|    fps              | 9645     |\n",
            "|    time_elapsed     | 0        |\n",
            "|    total_timesteps  | 2076     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.4     |\n",
            "|    ep_rew_mean      | 16.4     |\n",
            "|    exploration_rate | 0.293    |\n",
            "| time/               |          |\n",
            "|    episodes         | 200      |\n",
            "|    fps              | 2530     |\n",
            "|    time_elapsed     | 1        |\n",
            "|    total_timesteps  | 3721     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.275    |\n",
            "|    n_updates        | 180      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.2     |\n",
            "|    ep_rew_mean      | 10.2     |\n",
            "|    exploration_rate | 0.0994   |\n",
            "| time/               |          |\n",
            "|    episodes         | 300      |\n",
            "|    fps              | 1696     |\n",
            "|    time_elapsed     | 2        |\n",
            "|    total_timesteps  | 4740     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0466   |\n",
            "|    n_updates        | 434      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.55     |\n",
            "|    ep_rew_mean      | 9.55     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 400      |\n",
            "|    fps              | 1399     |\n",
            "|    time_elapsed     | 4        |\n",
            "|    total_timesteps  | 5695     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00189  |\n",
            "|    n_updates        | 673      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.48     |\n",
            "|    ep_rew_mean      | 9.48     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 500      |\n",
            "|    fps              | 1234     |\n",
            "|    time_elapsed     | 5        |\n",
            "|    total_timesteps  | 6643     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00205  |\n",
            "|    n_updates        | 910      |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.49     |\n",
            "|    ep_rew_mean      | 9.49     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 600      |\n",
            "|    fps              | 1134     |\n",
            "|    time_elapsed     | 6        |\n",
            "|    total_timesteps  | 7592     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.00357  |\n",
            "|    n_updates        | 1147     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.51     |\n",
            "|    ep_rew_mean      | 9.51     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 700      |\n",
            "|    fps              | 1042     |\n",
            "|    time_elapsed     | 8        |\n",
            "|    total_timesteps  | 8543     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000309 |\n",
            "|    n_updates        | 1385     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.84     |\n",
            "|    ep_rew_mean      | 9.84     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 800      |\n",
            "|    fps              | 951      |\n",
            "|    time_elapsed     | 10       |\n",
            "|    total_timesteps  | 9527     |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.000454 |\n",
            "|    n_updates        | 1631     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.66     |\n",
            "|    ep_rew_mean      | 9.66     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 900      |\n",
            "|    fps              | 927      |\n",
            "|    time_elapsed     | 11       |\n",
            "|    total_timesteps  | 10493    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.037    |\n",
            "|    n_updates        | 1873     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.78     |\n",
            "|    ep_rew_mean      | 9.78     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1000     |\n",
            "|    fps              | 908      |\n",
            "|    time_elapsed     | 12       |\n",
            "|    total_timesteps  | 11471    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0255   |\n",
            "|    n_updates        | 2117     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.76     |\n",
            "|    ep_rew_mean      | 9.76     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1100     |\n",
            "|    fps              | 893      |\n",
            "|    time_elapsed     | 13       |\n",
            "|    total_timesteps  | 12447    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0104   |\n",
            "|    n_updates        | 2361     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.63     |\n",
            "|    ep_rew_mean      | 9.63     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1200     |\n",
            "|    fps              | 880      |\n",
            "|    time_elapsed     | 15       |\n",
            "|    total_timesteps  | 13410    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0119   |\n",
            "|    n_updates        | 2602     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.57     |\n",
            "|    ep_rew_mean      | 9.57     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1300     |\n",
            "|    fps              | 870      |\n",
            "|    time_elapsed     | 16       |\n",
            "|    total_timesteps  | 14367    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0247   |\n",
            "|    n_updates        | 2841     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.4      |\n",
            "|    ep_rew_mean      | 9.4      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1400     |\n",
            "|    fps              | 862      |\n",
            "|    time_elapsed     | 17       |\n",
            "|    total_timesteps  | 15307    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0522   |\n",
            "|    n_updates        | 3076     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.5      |\n",
            "|    ep_rew_mean      | 9.5      |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1500     |\n",
            "|    fps              | 852      |\n",
            "|    time_elapsed     | 19       |\n",
            "|    total_timesteps  | 16257    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0145   |\n",
            "|    n_updates        | 3314     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.51     |\n",
            "|    ep_rew_mean      | 9.51     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1600     |\n",
            "|    fps              | 840      |\n",
            "|    time_elapsed     | 20       |\n",
            "|    total_timesteps  | 17208    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0262   |\n",
            "|    n_updates        | 3551     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.71     |\n",
            "|    ep_rew_mean      | 9.71     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1700     |\n",
            "|    fps              | 815      |\n",
            "|    time_elapsed     | 22       |\n",
            "|    total_timesteps  | 18179    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0088   |\n",
            "|    n_updates        | 3794     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.62     |\n",
            "|    ep_rew_mean      | 9.62     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1800     |\n",
            "|    fps              | 802      |\n",
            "|    time_elapsed     | 23       |\n",
            "|    total_timesteps  | 19141    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0305   |\n",
            "|    n_updates        | 4035     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.69     |\n",
            "|    ep_rew_mean      | 9.69     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 1900     |\n",
            "|    fps              | 799      |\n",
            "|    time_elapsed     | 25       |\n",
            "|    total_timesteps  | 20110    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.156    |\n",
            "|    n_updates        | 4277     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.54     |\n",
            "|    ep_rew_mean      | 9.54     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2000     |\n",
            "|    fps              | 797      |\n",
            "|    time_elapsed     | 26       |\n",
            "|    total_timesteps  | 21064    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0209   |\n",
            "|    n_updates        | 4515     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.85     |\n",
            "|    ep_rew_mean      | 9.85     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2100     |\n",
            "|    fps              | 795      |\n",
            "|    time_elapsed     | 27       |\n",
            "|    total_timesteps  | 22049    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0738   |\n",
            "|    n_updates        | 4762     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.83     |\n",
            "|    ep_rew_mean      | 9.83     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2200     |\n",
            "|    fps              | 791      |\n",
            "|    time_elapsed     | 29       |\n",
            "|    total_timesteps  | 23032    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0494   |\n",
            "|    n_updates        | 5007     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.83     |\n",
            "|    ep_rew_mean      | 9.83     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2300     |\n",
            "|    fps              | 789      |\n",
            "|    time_elapsed     | 30       |\n",
            "|    total_timesteps  | 24015    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0222   |\n",
            "|    n_updates        | 5253     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.72     |\n",
            "|    ep_rew_mean      | 9.72     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2400     |\n",
            "|    fps              | 786      |\n",
            "|    time_elapsed     | 31       |\n",
            "|    total_timesteps  | 24987    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0522   |\n",
            "|    n_updates        | 5496     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12       |\n",
            "|    ep_rew_mean      | 12       |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2500     |\n",
            "|    fps              | 770      |\n",
            "|    time_elapsed     | 33       |\n",
            "|    total_timesteps  | 26188    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0498   |\n",
            "|    n_updates        | 5796     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.3     |\n",
            "|    ep_rew_mean      | 16.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2600     |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 37       |\n",
            "|    total_timesteps  | 27816    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.083    |\n",
            "|    n_updates        | 6203     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 16.1     |\n",
            "|    ep_rew_mean      | 16.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2700     |\n",
            "|    fps              | 741      |\n",
            "|    time_elapsed     | 39       |\n",
            "|    total_timesteps  | 29421    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0383   |\n",
            "|    n_updates        | 6605     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.8     |\n",
            "|    ep_rew_mean      | 12.8     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2800     |\n",
            "|    fps              | 742      |\n",
            "|    time_elapsed     | 41       |\n",
            "|    total_timesteps  | 30701    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.268    |\n",
            "|    n_updates        | 6925     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.72     |\n",
            "|    ep_rew_mean      | 9.72     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 2900     |\n",
            "|    fps              | 743      |\n",
            "|    time_elapsed     | 42       |\n",
            "|    total_timesteps  | 31673    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.074    |\n",
            "|    n_updates        | 7168     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 10.1     |\n",
            "|    ep_rew_mean      | 10.1     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3000     |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 43       |\n",
            "|    total_timesteps  | 32680    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0488   |\n",
            "|    n_updates        | 7419     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 9.98     |\n",
            "|    ep_rew_mean      | 9.98     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3100     |\n",
            "|    fps              | 744      |\n",
            "|    time_elapsed     | 45       |\n",
            "|    total_timesteps  | 33678    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0525   |\n",
            "|    n_updates        | 7669     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 12.4     |\n",
            "|    ep_rew_mean      | 12.4     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3200     |\n",
            "|    fps              | 745      |\n",
            "|    time_elapsed     | 46       |\n",
            "|    total_timesteps  | 34922    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.142    |\n",
            "|    n_updates        | 7980     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 13.6     |\n",
            "|    ep_rew_mean      | 13.6     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3300     |\n",
            "|    fps              | 740      |\n",
            "|    time_elapsed     | 48       |\n",
            "|    total_timesteps  | 36282    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.09     |\n",
            "|    n_updates        | 8320     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 40.3     |\n",
            "|    ep_rew_mean      | 40.3     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3400     |\n",
            "|    fps              | 733      |\n",
            "|    time_elapsed     | 54       |\n",
            "|    total_timesteps  | 40313    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0218   |\n",
            "|    n_updates        | 9328     |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| rollout/            |          |\n",
            "|    ep_len_mean      | 27.7     |\n",
            "|    ep_rew_mean      | 27.7     |\n",
            "|    exploration_rate | 0.05     |\n",
            "| time/               |          |\n",
            "|    episodes         | 3500     |\n",
            "|    fps              | 734      |\n",
            "|    time_elapsed     | 58       |\n",
            "|    total_timesteps  | 43086    |\n",
            "| train/              |          |\n",
            "|    learning_rate    | 0.0001   |\n",
            "|    loss             | 0.0667   |\n",
            "|    n_updates        | 10021    |\n",
            "----------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.dqn.dqn.DQN at 0x7f1a9039fe50>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the agent for 50000 steps\n",
        "dqn_mlp.learn(total_timesteps=50000, log_interval=100, progress_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "uowI-OkYvE3S",
        "outputId": "324e0688-c30f-41cb-cb01-a7b91c8dfb08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 139.88 Std reward: 7.784422154715678 Num episodes: 100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:<ipython-input-11-afd6aa70d858>:28: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  std_episode_reward = np.std(all_episode_rewards) / np.sqrt(num_episodes - 1)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean reward: 74.0 Std reward: nan Num episodes: 1\n",
            "Moviepy - Building video temp-{start}.mp4.\n",
            "Moviepy - Writing video temp-{start}.mp4\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready temp-{start}.mp4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate the trained models\n",
        "dqn_mlp_mean, dqn_mlp_std = evaluate(env, dqn_mlp)\n",
        "\n",
        "_, _ = evaluate(env_eval, dqn_mlp, num_episodes=1)\n",
        "env_eval.play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljAhob-XvE3S"
      },
      "source": [
        "Let us now plot the final results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "kBNTTXoavE3S",
        "outputId": "06b2914e-a3ca-48c0-fa91-45d90740f29a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Plot the results\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "algs = ['Random', 'Reactive', 'PPO MLP', 'PPO Linear', 'DQN']\n",
        "means = [uniform_policy_mean, reactive_policy_mean, ppo_mlp_mean, ppo_linear_mean, dqn_mlp_mean]\n",
        "errors = [uniform_policy_std, reactive_policy_std, ppo_mlp_std, ppo_linear_std, dqn_mlp_std]\n",
        "\n",
        "ax.bar(algs, means, yerr=errors, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6524b65fc3fb4f11bb721c4608463fef": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_f17ddede3cdf4a5cbd295211c51d9e8e",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">51,165/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:12</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">391 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51,165/50,000 \u001b[0m [ \u001b[33m0:02:12\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m391 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "6a73f78210424ad3b954db2285ae7961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0456c21d7684db0b9bd0bff83dfbe57": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_ea851811079942b3b20cb106069cba92",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span> <span style=\"color: #008000; text-decoration-color: #008000\">49,905/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:01:08</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:01</span> , <span style=\"color: #800000; text-decoration-color: #800000\">709 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m49,905/50,000 \u001b[0m [ \u001b[33m0:01:08\u001b[0m < \u001b[36m0:00:01\u001b[0m , \u001b[31m709 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "d18154d71d4a4541a7a727779aa34dda": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6a73f78210424ad3b954db2285ae7961",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\"> 100%</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">51,155/50,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">0:02:00</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> , <span style=\"color: #800000; text-decoration-color: #800000\">329 it/s</span> ]\n</pre>\n",
                  "text/plain": "\u001b[35m 100%\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51,155/50,000 \u001b[0m [ \u001b[33m0:02:00\u001b[0m < \u001b[36m0:00:00\u001b[0m , \u001b[31m329 it/s\u001b[0m ]\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        },
        "ea851811079942b3b20cb106069cba92": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17ddede3cdf4a5cbd295211c51d9e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
